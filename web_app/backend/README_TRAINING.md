# ğŸš€ æ¨¡å‹è®­ç»ƒæŒ‡å—

## ğŸ“‹ æ–‡ä»¶è¯´æ˜

### è®­ç»ƒç›¸å…³æ–‡ä»¶
- `train_model.py` - ä¸»è®­ç»ƒè„šæœ¬ï¼ˆä½¿ç”¨è‹±æ–‡GPT-2ï¼‰
- `training_data_interpretation_en.csv` - è‹±æ–‡è®­ç»ƒæ•°æ®ï¼ˆ45æ¡ï¼‰
- `generate_interpretation_en.py` - æ¨ç†æ¨¡å—
- `species_name_mapping.json` - ä¸­æ–‡åˆ°è‹±æ–‡ç‰©ç§åç§°æ˜ å°„

### é›†æˆæ–‡ä»¶
- `enhanced_ai_assistant.py` - å·²é›†æˆæ¨¡å‹ç”ŸæˆåŠŸèƒ½

## ğŸ¯ è®­ç»ƒæ­¥éª¤

### 1. å®‰è£…ä¾èµ–
```bash
cd web_app/backend
source venv/bin/activate
pip install torch transformers pandas numpy tqdm nltk
```

### 2. å‡†å¤‡æ•°æ®
æ•°æ®æ–‡ä»¶å·²å‡†å¤‡å¥½ï¼š`training_data_interpretation_en.csv`

æ•°æ®æ ¼å¼ï¼š
- `species_en`: è‹±æ–‡ç‰©ç§åç§°
- `category`: ç±»åˆ«ï¼ˆfun_fact, behavior, habitatï¼‰
- `interpretation_text`: è‹±æ–‡è§£è¯»æ–‡æœ¬

### 3. å¼€å§‹è®­ç»ƒ
```bash
python train_model.py
```

è®­ç»ƒå‚æ•°ï¼ˆå¯åœ¨è„šæœ¬ä¸­ä¿®æ”¹ï¼‰ï¼š
- Epochs: 10
- Batch size: 4
- Learning rate: 5e-5
- Max length: 256

### 4. æ£€æŸ¥è®­ç»ƒç»“æœ
è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹ä¼šä¿å­˜åˆ°ï¼š`models/interpretation_model/`

æŸ¥çœ‹è®­ç»ƒå†å²ï¼š
```bash
cat models/interpretation_model/training_history.json | python3 -m json.tool
```

### 5. æµ‹è¯•ç”Ÿæˆ
```bash
python generate_interpretation_en.py
```

## ğŸ”§ è¾“å…¥æ ¼å¼

è®­ç»ƒæ—¶ä½¿ç”¨çš„è¾“å…¥æ ¼å¼ï¼š
```
Species: {species_en}, Category: {category}, Interpretation: {interpretation_text}
```

ç”Ÿæˆæ—¶ä½¿ç”¨çš„è¾“å…¥æ ¼å¼ï¼š
```
Species: {species_en}, Category: {category}, Interpretation:
```

## ğŸ“Š æ¨¡å‹ç‰¹ç‚¹

1. **çº¯è‹±æ–‡è¾“å…¥è¾“å‡º**ï¼šé¿å…ä¸­è‹±æ–‡æ··åˆå¯¼è‡´çš„æ¨¡å‹æ··æ·†
2. **ç»“æ„åŒ–è¾“å…¥**ï¼šä½¿ç”¨"Species: ... Category: ..."æ ¼å¼ï¼Œå¸®åŠ©æ¨¡å‹ç†è§£ç»“æ„
3. **ç‰©ç§åç§°æ˜ å°„**ï¼šæ”¯æŒä¸­æ–‡ç‰©ç§åç§°è‡ªåŠ¨è½¬æ¢ä¸ºè‹±æ–‡

## ğŸ¨ ä½¿ç”¨ç¤ºä¾‹

### åœ¨ä»£ç ä¸­ä½¿ç”¨
```python
from generate_interpretation_en import InterpretationGenerator

generator = InterpretationGenerator('models/interpretation_model')
result = generator.generate("Taiwan Blue Magpie", "fun_fact")
# æˆ–è€…ä½¿ç”¨ä¸­æ–‡åç§°ï¼ˆä¼šè‡ªåŠ¨è½¬æ¢ï¼‰
result = generator.generate("è‡ºç£è—éµ²", "fun_fact")
```

### åœ¨AIåŠ©æ‰‹ä¸­
æ¨¡å‹å·²è‡ªåŠ¨é›†æˆåˆ° `enhanced_ai_assistant.py`ï¼Œå½“ç”¨æˆ·è¯¢é—®ç‰©ç§ä¿¡æ¯æ—¶ä¼šè‡ªåŠ¨è§¦å‘ã€‚

## âš™ï¸ è‡ªå®šä¹‰è®­ç»ƒ

### ä¿®æ”¹è®­ç»ƒå‚æ•°
ç¼–è¾‘ `train_model.py` ä¸­çš„ `train_model()` å‡½æ•°è°ƒç”¨ï¼š

```python
train_model(
    csv_path='training_data_interpretation_en.csv',
    output_dir='models/interpretation_model',
    num_epochs=10,      # ä¿®æ”¹è®­ç»ƒè½®æ•°
    batch_size=4,       # ä¿®æ”¹æ‰¹æ¬¡å¤§å°
    learning_rate=5e-5, # ä¿®æ”¹å­¦ä¹ ç‡
    max_length=256,     # ä¿®æ”¹æœ€å¤§é•¿åº¦
    warmup_steps=50     # ä¿®æ”¹é¢„çƒ­æ­¥æ•°
)
```

### æ·»åŠ æ›´å¤šè®­ç»ƒæ•°æ®
ç¼–è¾‘ `training_data_interpretation_en.csv`ï¼Œæ·»åŠ æ›´å¤šæ•°æ®ï¼š
- ä¿æŒæ ¼å¼ä¸€è‡´
- ä½¿ç”¨è‹±æ–‡ç‰©ç§åç§°
- ä½¿ç”¨è‹±æ–‡è§£è¯»æ–‡æœ¬

## ğŸ“ˆ è®­ç»ƒæŒ‡æ ‡

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šæ˜¾ç¤ºï¼š
- **Training loss**: è®­ç»ƒæŸå¤±ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
- **Validation loss**: éªŒè¯æŸå¤±ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
- **Perplexity**: å›°æƒ‘åº¦ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
- **BLEU score**: BLEUåˆ†æ•°ï¼ˆè¶Šé«˜è¶Šå¥½ï¼Œæ¯2ä¸ªepochè®¡ç®—ä¸€æ¬¡ï¼‰

æœ€ä½³æ¨¡å‹ä¼šæ ¹æ®éªŒè¯æŸå¤±è‡ªåŠ¨ä¿å­˜ã€‚

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ•°æ®é‡**ï¼šå½“å‰åªæœ‰45æ¡æ•°æ®ï¼Œå»ºè®®å¢åŠ åˆ°200-500æ¡ä»¥è·å¾—æ›´å¥½æ•ˆæœ
2. **è®­ç»ƒæ—¶é—´**ï¼šæ ¹æ®ç¡¬ä»¶é…ç½®ï¼Œ10ä¸ªepochå¯èƒ½éœ€è¦30-60åˆ†é’Ÿ
3. **GPUæ”¯æŒ**ï¼šå¦‚æœæœ‰GPUä¼šè‡ªåŠ¨ä½¿ç”¨ï¼Œå¦åˆ™ä½¿ç”¨CPUï¼ˆè¾ƒæ…¢ï¼‰
4. **æ¨¡å‹å¤§å°**ï¼šè®­ç»ƒå¥½çš„æ¨¡å‹çº¦475MB

## âœ… å®Œæˆæ£€æŸ¥

è®­ç»ƒå®Œæˆåæ£€æŸ¥ï¼š
1. âœ… æ¨¡å‹æ–‡ä»¶å­˜åœ¨ï¼š`models/interpretation_model/model.safetensors`
2. âœ… è®­ç»ƒå†å²å­˜åœ¨ï¼š`models/interpretation_model/training_history.json`
3. âœ… æµ‹è¯•ç”ŸæˆæˆåŠŸï¼šè¿è¡Œ `python generate_interpretation_en.py`

ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼ğŸ‰

